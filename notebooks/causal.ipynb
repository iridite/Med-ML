{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":20270,"databundleVersionId":1222630,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install timm -q\n# å¦‚æžœéœ€è¦ albumentations æœ€æ–°ç‰ˆ\n# !pip install -U albumentations -q\n\nimport os\n# å®‰è£… timm\nos.system('pip install timm -q')\nprint(\"âœ… Environment setup complete.\")\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport random\nimport torch","metadata":{"_uuid":"19f48e87-adf7-4845-9dc3-0974f7e3559f","_cell_guid":"c86b8e9f-60c4-463e-997a-7c1f1ea6d836","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2026-01-08T05:29:26.405842Z","iopub.execute_input":"2026-01-08T05:29:26.406105Z","iopub.status.idle":"2026-01-08T05:29:30.481555Z","shell.execute_reply.started":"2026-01-08T05:29:26.406073Z","shell.execute_reply":"2026-01-08T05:29:30.480818Z"}},"outputs":[{"name":"stdout","text":"âœ… Environment setup complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === å…¨å±€é…ç½® ===\nclass Config:\n    # åŸºç¡€å‚æ•°\n    SEED = 42\n    IMG_SIZE = 224\n    BATCH_SIZE = 32     # å¦‚æžœæ˜¾å­˜ç‚¸äº†ï¼Œæ”¹æˆ 16\n    EPOCHS = 5          # Kaggleä¸Šè·‘5è½®åšæ¼”ç¤º\n    LR = 3e-4\n    NUM_WORKERS = 2     # Kaggle çŽ¯å¢ƒè®¾å¤ªå¤§å®¹æ˜“ Shared Memory Error\n    \n    # è®¾å¤‡\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    # è·¯å¾„å ä½ç¬¦\n    # DATA_ROOT_DIR = \"\"\n    # TRAIN_CSV = \"\"\n    # TRAIN_IMG_DIR = \"\"","metadata":{"_uuid":"19f48e87-adf7-4845-9dc3-0974f7e3559f","_cell_guid":"c86b8e9f-60c4-463e-997a-7c1f1ea6d836","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2026-01-04T14:44:32.985212Z","iopub.execute_input":"2026-01-04T14:44:32.985519Z","iopub.status.idle":"2026-01-04T14:44:32.992638Z","shell.execute_reply.started":"2026-01-04T14:44:32.985482Z","shell.execute_reply":"2026-01-04T14:44:32.991707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    print(f\"âœ… Random Seed Set: {seed}\")\n\n# === æ•°æ®é›†è‡ªåŠ¨å‘çŽ°ä¸Žç”¨æˆ·æŒ‡å®šé€»è¾‘ ===\ndef setup_directories():\n    print(\"ðŸ” Searching for dataset...\")\n    \n    # å¸¸è§çš„ Kaggle æ•°æ®é›†æŒ‚è½½è·¯å¾„\n    candidate_paths = [\n        \"/kaggle/input/siim-isic-melanoma-classification\",\n        \"../input/siim-isic-melanoma-classification\"\n    ]\n    \n    found_path = None\n    for p in candidate_paths:\n        if os.path.exists(p) and os.path.exists(os.path.join(p, \"train.csv\")):\n            found_path = p\n            break\n    \n    # å¦‚æžœæ‰¾ä¸åˆ°ï¼Œå¼ºåˆ¶ç­‰å¾…ç”¨æˆ·è¾“å…¥\n    if found_path is None:\n        print(\"\\nâŒ Warning: Could not automatically find 'train.csv'.\")\n        print(\"Please look at the 'Data' panel on the right side.\")\n        user_input = input(\"ðŸ‘‰ Please PASTE the full path to the dataset directory (where train.csv is located): \")\n        user_input = user_input.strip()\n        \n        if os.path.exists(os.path.join(user_input, \"train.csv\")):\n            found_path = user_input\n        else:\n            raise FileNotFoundError(f\"Could not find train.csv in {user_input}\")\n\n    # è·¯å¾„ç¡®è®¤\n    Config.DATA_ROOT_DIR = found_path\n    Config.TRAIN_CSV = os.path.join(found_path, \"train.csv\")\n    \n    # æ£€æŸ¥ jpeg ç›®å½• (æœ‰æ—¶å€™æ˜¯ train/, æœ‰æ—¶å€™æ˜¯ jpeg/train/)\n    possible_img_dirs = [\"jpeg/train\", \"train\"]\n    img_dir_final = None\n    for sub in possible_img_dirs:\n        check = os.path.join(found_path, sub)\n        if os.path.exists(check):\n            img_dir_final = check\n            break\n            \n    if img_dir_final is None:\n         # å†æ¬¡fallbackï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šå›¾ç‰‡ä½ç½®\n         img_dir_final = input(f\"ðŸ‘‰ found train.csv but NOT image dir. Paste full path to train images folder: \")\n    \n    Config.TRAIN_IMG_DIR = img_dir_final\n    \n    print(\"\\nâœ… Dataset Configured Successfully:\")\n    print(f\"   CSV Path: {Config.TRAIN_CSV}\")\n    print(f\"   Img Path: {Config.TRAIN_IMG_DIR}\")\n\n# è¿è¡Œé…ç½®\nseed_everything(Config.SEED)\nsetup_directories()","metadata":{"_uuid":"19f48e87-adf7-4845-9dc3-0974f7e3559f","_cell_guid":"c86b8e9f-60c4-463e-997a-7c1f1ea6d836","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2026-01-04T14:48:34.619849Z","iopub.execute_input":"2026-01-04T14:48:34.620239Z","iopub.status.idle":"2026-01-04T14:48:34.639642Z","shell.execute_reply.started":"2026-01-04T14:48:34.620208Z","shell.execute_reply":"2026-01-04T14:48:34.638788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass MelanomaDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        \n        self.image_ids = self.df['image_name'].values\n        self.targets = self.df['target'].values\n        \n        # === æ ¸å¿ƒé€»è¾‘ï¼šå®šä¹‰æœ‰æ•ˆç‰¹å¾ä¸Žå› æžœé»‘åå• ===\n        # 1. å‰”é™¤ ID ç±»ä¿¡æ¯\n        # 2. å‰”é™¤ æ•°æ®æ³„éœ²åˆ— (diagnosis, benign_malignant)\n        # 3. å‰”é™¤ å› æžœæƒé‡åˆ—\n        ignore_cols = [\n            'image_name', 'patient_id', 'target', 'causal_weight', \n            'diagnosis', 'benign_malignant' \n        ]\n        \n        # ç­›é€‰å‰©ä¸‹çš„åˆ—ä½œä¸º tabular features\n        self.meta_cols = [c for c in self.df.columns if c not in ignore_cols]\n        self.meta_features = self.df[self.meta_cols].values\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # 1. è¯»å›¾\n        img_id = self.image_ids[idx]\n        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n        image = cv2.imread(img_path)\n        \n        # é˜²å¾¡æ€§ä»£ç \n        if image is None:\n            image = np.zeros((Config.IMG_SIZE, Config.IMG_SIZE, 3), dtype=np.uint8)\n        else:\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # 2. å¢žå¼º\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        \n        # 3. æå–ç‰¹å¾å’Œæ ‡ç­¾\n        meta = torch.tensor(self.meta_features[idx], dtype=torch.float32)\n        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n        \n        # 4. ã€å› æžœæŽ¨æ–­æŽ¥å£ã€‘æå–æƒé‡\n        if 'causal_weight' in self.df.columns:\n            weight = torch.tensor(self.df.iloc[idx]['causal_weight'], dtype=torch.float32)\n        else:\n            weight = torch.tensor(1.0, dtype=torch.float32)\n            \n        return image, meta, target, weight\n\ndef get_preprocessed_df(csv_path):\n    print(\"â³ Preprocessing CSV data...\")\n    df = pd.read_csv(csv_path)\n    \n    # å¡«å……ç¼ºå¤±å€¼\n    # æ³¨æ„ï¼šçœŸå®žé¡¹ç›®ä¸­å¯èƒ½è¦å…ˆæ ¹æ® Training Set ç®— meanï¼Œç„¶åŽåº”ç”¨åˆ° Test Set\n    df['anatom_site_general_challenge'] = df['anatom_site_general_challenge'].fillna('unknown')\n    df['sex'] = df['sex'].fillna('unknown')\n    \n    # å¤„ç†å¹´é¾„ (å¡«å‡å€¼ + ç®€å•å½’ä¸€åŒ–)\n    df['age_approx'] = df['age_approx'].fillna(df['age_approx'].mean())\n    df['age_approx'] = df['age_approx'] / 100.0\n    \n    # One-Hot ç¼–ç  (è½¬æ¢æ–‡æœ¬ä¸ºæ•°å­—)\n    df = pd.get_dummies(df, columns=['sex', 'anatom_site_general_challenge'], prefix=['sex', 'site'], dtype=float)\n    \n    print(f\"âœ… Feature processing done. Total samples: {len(df)}\")\n    return df\n\nimport torch.nn as nn\nimport timm\n\nclass CausalFusionModel(nn.Module):\n    def __init__(self, meta_features_dim, out_dim=1, pretrained=True):\n        super().__init__()\n        \n        # 1. Image Branch\n        # Kaggle æ— ç½‘ç»œçŽ¯å¢ƒä¸‹å¦‚æžœtimmn downloadå¤±è´¥ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨ä¸Šä¼ æƒé‡\n        # æ­£å¸¸æœ‰ç½‘çŠ¶æ€ä¸‹è®¾ä¸º True å³å¯\n        self.backbone = timm.create_model('efficientnet_b0', pretrained=pretrained, num_classes=0, in_chans=3)\n        self.img_dim = self.backbone.num_features # 1280\n        \n        # 2. Tabular Branch\n        self.meta_net = nn.Sequential(\n            nn.Linear(meta_features_dim, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 128),\n            nn.ReLU()\n        )\n        self.meta_dim = 128\n        \n        # 3. Heads\n        total_dim = self.img_dim + self.meta_dim\n        \n        # Main Prediction Head\n        self.classifier = nn.Linear(total_dim, out_dim)\n        \n        # ã€å› æžœæŽ¥å£ã€‘ Auxiliary Head for De-confounding\n        self.confounder_head = nn.Linear(total_dim, 5) # Placeholder\n\n    def forward(self, image, meta, return_features=False):\n        # Image -> [B, 1280]\n        x_img = self.backbone(image)\n        # Table -> [B, 128]\n        x_meta = self.meta_net(meta)\n        \n        # Concatenate -> [B, 1408]\n        # è¿™æ˜¯å› æžœè¡¨å¾çš„æ ¸å¿ƒå±‚\n        features = torch.cat((x_img, x_meta), dim=1)\n        \n        logits = self.classifier(features)\n        \n        if return_features:\n            return logits, features\n        \n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:50:19.093733Z","iopub.execute_input":"2026-01-04T14:50:19.094084Z","iopub.status.idle":"2026-01-04T14:50:29.291702Z","shell.execute_reply.started":"2026-01-04T14:50:19.094054Z","shell.execute_reply":"2026-01-04T14:50:29.291033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\nfrom sklearn.metrics import roc_auc_score\nfrom torch.utils.data import random_split\nfrom tqdm.notebook import tqdm # ä½¿ç”¨ notebook ä¸“ç”¨çš„è¿›åº¦æ¡\n\ndef train_epoch(model, loader, criterion, optimizer, epoch):\n    model.train()\n    running_loss = 0.0\n    # åœ¨ Notebook é‡Œå°½é‡å‡å°‘ tqdm æ‰“å°é¢‘çŽ‡\n    \n    for images, metas, targets, weights in tqdm(loader, desc=f\"Epoch {epoch} Train\", leave=False):\n        images, metas = images.to(Config.DEVICE), metas.to(Config.DEVICE)\n        targets = targets.to(Config.DEVICE).unsqueeze(1)\n        weights = weights.to(Config.DEVICE).unsqueeze(1)\n        \n        optimizer.zero_grad()\n        \n        # å‰å‘\n        logits = model(images, metas)\n        \n        # å› æžœ Loss è®¡ç®—\n        loss_per_sample = criterion(logits, targets)\n        loss = (loss_per_sample * weights).mean()\n        \n        # åå‘\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n    return running_loss / len(loader)\n\ndef validate_epoch(model, loader, criterion):\n    model.eval()\n    val_loss = 0.0\n    preds = []\n    truths = []\n    \n    with torch.no_grad():\n        for images, metas, targets, _ in tqdm(loader, desc=\"Validating\", leave=False):\n            images, metas = images.to(Config.DEVICE), metas.to(Config.DEVICE)\n            targets_gpu = targets.to(Config.DEVICE).unsqueeze(1)\n            \n            logits = model(images, metas)\n            loss = criterion(logits, targets_gpu)\n            val_loss += loss.item()\n            \n            # è®°å½•ç»“æžœç®— AUC\n            probs = torch.sigmoid(logits).cpu().numpy()\n            preds.extend(probs)\n            truths.extend(targets.numpy())\n            \n    try:\n        auc = roc_auc_score(truths, preds)\n    except:\n        auc = 0.5\n        \n    return val_loss / len(loader), auc\n\n# === ä¸»æ‰§è¡Œæµ ===\ndef main():\n    # 1. å‡†å¤‡æ•°æ®\n    df = get_preprocessed_df(Config.TRAIN_CSV)\n    \n    # å›¾åƒå¢žå¼º (Training)\n    train_transforms = A.Compose([\n        A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5), # å¢žåŠ ä¸€ç‚¹éš¾åº¦\n        A.Normalize(),\n        ToTensorV2()\n    ])\n    \n    # å›¾åƒå¢žå¼º (Validation - åªåš Normalize)\n    val_transforms = A.Compose([\n        A.Resize(Config.IMG_SIZE, Config.IMG_SIZE),\n        A.Normalize(),\n        ToTensorV2()\n    ])\n    \n    # ä¸ºäº†æ¼”ç¤ºç®€å•ï¼Œæˆ‘ä»¬ç›´æŽ¥ split è¿™ä¸ª DataFrame\n    # å®žé™… Kaggle æ¯”èµ›åº”è¯¥ä½¿ç”¨ StratifiedKFold\n    from sklearn.model_selection import train_test_split\n    df_train, df_val = train_test_split(df, test_size=0.2, random_state=Config.SEED, stratify=df['target'])\n    \n    # æž„å»º Datasets\n    train_ds = MelanomaDataset(df_train.reset_index(drop=True), Config.TRAIN_IMG_DIR, transform=train_transforms)\n    val_ds = MelanomaDataset(df_val.reset_index(drop=True), Config.TRAIN_IMG_DIR, transform=val_transforms)\n    \n    # æž„å»º DataLoaders\n    train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True, \n                              num_workers=Config.NUM_WORKERS, pin_memory=True)\n    val_loader = DataLoader(val_ds, batch_size=Config.BATCH_SIZE, shuffle=False, \n                            num_workers=Config.NUM_WORKERS, pin_memory=True)\n    \n    print(f\"ðŸ“Š Training Samples: {len(train_ds)} | Validation Samples: {len(val_ds)}\")\n    \n    # 2. åˆå§‹åŒ–æ¨¡åž‹\n    # èŽ·å–åŠ¨æ€çš„è¡¨æ ¼åˆ—æ•°\n    meta_dim = train_ds.meta_features.shape[1]\n    print(f\"ðŸ§  Meta Features Dim: {meta_dim}\")\n    \n    model = CausalFusionModel(meta_features_dim=meta_dim).to(Config.DEVICE)\n    \n    # 3. è®¾ç½®è®­ç»ƒç»„ä»¶\n    # å› æžœåŠ æƒè®­ç»ƒè¦æ±‚ Loss Reduction ä¸º None\n    # pos_weight=torch.tensor([20.0]) ç”¨äºŽåº”å¯¹ç±»åˆ«æžå…¶ä¸å¹³è¡¡ (å› ä¸ºçš®è‚¤ç™Œé˜³æ€§æ ·æœ¬å¾ˆå°‘)\n    # åœ¨è¿™ä¸ª MVP ä¸­æˆ‘ä»¬å¯ä»¥å…ˆæ³¨é‡ŠæŽ‰ pos_weight çœ‹åŽŸç”Ÿæ•ˆæžœï¼Œæˆ–è€…æ‰‹åŠ¨è®¾ç½®\n    criterion = nn.BCEWithLogitsLoss(reduction='none') \n    optimizer = optim.AdamW(model.parameters(), lr=Config.LR)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.EPOCHS)\n    \n    # 4. å¼€å§‹ Loop\n    best_auc = 0.0\n    for epoch in range(1, Config.EPOCHS + 1):\n        print(f\"\\n--- Epoch {epoch}/{Config.EPOCHS} ---\")\n        \n        train_loss = train_epoch(model, train_loader, criterion, optimizer, epoch)\n        val_loss, val_auc = validate_epoch(model, val_loader, criterion)\n        \n        scheduler.step()\n        \n        print(f\"Train Loss: {train_loss:.4f}\")\n        print(f\"Valid Loss: {val_loss:.4f} | AUC: {val_auc:.4f}\")\n        \n        if val_auc > best_auc:\n            best_auc = val_auc\n            torch.save(model.state_dict(), \"best_causal_model.pth\")\n            print(\"ðŸŒŸ Best Model Saved!\")\n            \n    print(f\"\\nâœ… Training Complete. Best AUC: {best_auc:.4f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2026-01-04T13:10:14.589274Z","iopub.execute_input":"2026-01-04T13:10:14.589584Z","iopub.status.idle":"2026-01-04T13:10:17.564204Z","shell.execute_reply.started":"2026-01-04T13:10:14.589560Z","shell.execute_reply":"2026-01-04T13:10:17.562972Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}